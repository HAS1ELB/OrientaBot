"""
Simple chat handler for API routes - lightweight version without complex dependencies
"""
import os
import json
import logging
from typing import List, Dict, Optional, Any, Generator
from groq import Groq
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)

class SimpleChatHandler:
    """Simple chat handler for API integration"""
    
    def __init__(self):
        """Initialize the simple chat handler"""
        self.groq_api_key = os.getenv("GROQ_API_KEY")
        self.groq_model = os.getenv("GROQ_MODEL", "llama3-70b-8192")
        self.max_tokens = int(os.getenv("MAX_TOKENS", "4000"))
        
        if not self.groq_api_key or self.groq_api_key == "gsk_placeholder_key_here":
            logger.warning("âš ï¸ Groq API key not configured - using fallback responses")
            self.client = None
        else:
            self.client = Groq(api_key=self.groq_api_key)
            logger.info("âœ… Groq client initialized successfully")
    
    def process_message(self, 
                       message: str,
                       conversation_history: List[Dict[str, str]] = None,
                       temperature: float = 0.7,
                       session_id: str = None) -> Dict[str, Any]:
        """
        Process a chat message and return response
        
        Args:
            message: User message
            conversation_history: Previous conversation
            temperature: Model temperature
            session_id: Session identifier
            
        Returns:
            Dict with response and metadata
        """
        if conversation_history is None:
            conversation_history = []
        
        try:
            if not self.client:
                return self._fallback_response(message, session_id)
            
            # Build messages for Groq API
            messages = [
                {
                    "role": "system",
                    "content": self._get_system_prompt()
                }
            ]
            
            # Add conversation history
            messages.extend(conversation_history)
            
            # Add current message
            messages.append({"role": "user", "content": message})
            
            # Generate response
            response = self.client.chat.completions.create(
                model=self.groq_model,
                messages=messages,
                temperature=temperature,
                max_tokens=self.max_tokens,
                stream=False
            )
            
            response_text = response.choices[0].message.content
            
            return {
                "status": "success",
                "response": response_text,
                "session_id": session_id,
                "recommendations": self._extract_recommendations(response_text),
                "rag_available": False,
                "stats": {"groq_model_used": self.groq_model}
            }
            
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            return {
                "status": "error",
                "response": f"DÃ©solÃ©, une erreur s'est produite: {str(e)}",
                "session_id": session_id,
                "error": str(e)
            }
    
    def stream_message(self, 
                      message: str,
                      conversation_history: List[Dict[str, str]] = None,
                      temperature: float = 0.7,
                      session_id: str = None) -> Generator[str, None, None]:
        """
        Stream a chat message response
        """
        if conversation_history is None:
            conversation_history = []
        
        try:
            if not self.client:
                # Fallback streaming
                fallback = self._fallback_response(message, session_id)
                for word in fallback["response"].split():
                    yield word + " "
                return
            
            # Build messages for Groq API
            messages = [
                {
                    "role": "system", 
                    "content": self._get_system_prompt()
                }
            ]
            
            # Add conversation history
            messages.extend(conversation_history)
            
            # Add current message
            messages.append({"role": "user", "content": message})
            
            # Stream response
            response = self.client.chat.completions.create(
                model=self.groq_model,
                messages=messages,
                temperature=temperature,
                max_tokens=self.max_tokens,
                stream=True
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            logger.error(f"Error streaming message: {e}")
            yield f"Erreur: {str(e)}"
    
    def _get_system_prompt(self) -> str:
        """Get the system prompt for OrientaBot"""
        return """Tu es Dr. Karima Benjelloun, conseillÃ¨re d'orientation expÃ©rimentÃ©e spÃ©cialisÃ©e dans le systÃ¨me Ã©ducatif marocain.

**Ton expertise couvre:**
- Les Ã©coles d'ingÃ©nieurs (ENSA, EMSI, ISPITS, etc.)
- Les seuils d'admission et critÃ¨res de sÃ©lection
- Les filiÃ¨res d'Ã©tudes et dÃ©bouchÃ©s professionnels
- L'orientation post-bac au Maroc
- Les carriÃ¨res dans l'IA, l'informatique et l'ingÃ©nierie

**Pour les questions sur les seuils d'admission:**
- ENSA: GÃ©nÃ©ralement entre 16-18/20 selon les spÃ©cialitÃ©s et concours
- EMSI: Environ 12-14/20 pour la plupart des filiÃ¨res
- ISPITS: Environ 14-16/20 selon les programmes

**Ton approche:**
1. Analyse le profil de l'Ã©tudiant (filiÃ¨re, moyenne, intÃ©rÃªts)
2. Fournis des conseils personnalisÃ©s et pratiques
3. SuggÃ¨re des alternatives et plans B
4. Encourage et rassure tout en restant rÃ©aliste

RÃ©ponds en franÃ§ais avec empathie, expertise et des conseils concrets adaptÃ©s au systÃ¨me Ã©ducatif marocain."""
    
    def _fallback_response(self, message: str, session_id: str) -> Dict[str, Any]:
        """Fallback response when Groq API is not available"""
        
        # Simple pattern matching for common questions
        message_lower = message.lower()
        
        if "seuil" in message_lower and "ensa" in message_lower:
            response = """ðŸŽ“ **Seuils d'admission ENSA (Ã‰cole Nationale des Sciences AppliquÃ©es)**

Les seuils ENSA varient selon:
- **La ville/Ã©cole**: ENSA Agadir, El Jadida, FÃ¨s, Marrakech, etc.
- **La spÃ©cialitÃ©**: Informatique, GÃ©nie Civil, Ã‰lectronique, etc.
- **L'annÃ©e**: Les seuils Ã©voluent chaque annÃ©e

**Seuils indicatifs 2023-2024:**
- **GÃ©nÃ©ral**: 16-18/20 selon les spÃ©cialitÃ©s
- **Informatique/IA**: Souvent 17-18/20 (trÃ¨s demandÃ©)
- **GÃ©nie Civil**: 16-17/20
- **Ã‰lectronique**: 16.5-17.5/20

**Avec votre moyenne de 15/20:**
- C'est en dessous des seuils ENSA habituels
- Concentrez-vous sur amÃ©liorer vos notes en terminale
- ConsidÃ©rez aussi EMSI, ISPITS comme alternatives excellentes
- PrÃ©parez bien le concours national si applicable

âš ï¸ *VÃ©rifiez les seuils officiels sur les sites des Ã©coles*"""
        
        elif "ia" in message_lower or "intelligence artificielle" in message_lower:
            response = """ðŸ¤– **Devenir IngÃ©nieur en IA au Maroc**

**Ã‰coles recommandÃ©es pour l'IA:**
1. **ENSA** - GÃ©nie Informatique/TÃ©lÃ©coms (seuil ~17-18/20)
2. **EMSI** - Intelligence Artificielle (seuil ~14/20)
3. **ISPITS** - Data Science et IA (seuil ~15/20)
4. **UniversitÃ© Hassan II** - Master IA (aprÃ¨s licence)

**Avec SM-B et 15/20:**
- âœ… **EMSI**: Excellente option, programmes IA solides
- âœ… **ISPITS**: Bons programmes, seuil accessible
- ðŸŽ¯ **Objectif**: AmÃ©liorer Ã  16-17/20 pour plus d'options
- ðŸ“š **Conseils**: Renforcez maths/physique, apprenez Python

**Plan d'action:**
1. Travaillez pour atteindre 16/20 minimum
2. Explorez EMSI et ISPITS dÃ¨s maintenant
3. DÃ©veloppez des projets perso en IA
4. PrÃ©parez-vous aux entretiens techniques"""
        
        else:
            response = f"""ðŸ‘‹ Bonjour ! Je suis Dr. Karima Benjelloun, votre conseillÃ¨re d'orientation.

J'ai bien reÃ§u votre question: "{message}"

Pour vous donner les meilleurs conseils, j'aimerais en savoir plus sur:
- ðŸ“š Votre filiÃ¨re actuelle et vos rÃ©sultats
- ðŸŽ¯ Vos objectifs de carriÃ¨re
- â¤ï¸ Vos passions et centres d'intÃ©rÃªt
- ðŸ›ï¸ Les Ã©coles qui vous intÃ©ressent

*Note: Pour des conseils plus prÃ©cis, assurez-vous que l'API Groq est configurÃ©e avec une vraie clÃ©.*"""
        
        return {
            "status": "success",
            "response": response,
            "session_id": session_id,
            "recommendations": {"mode": "fallback"},
            "rag_available": False,
            "stats": {"mode": "fallback"}
        }
    
    def _extract_recommendations(self, response_text: str) -> Optional[Dict[str, Any]]:
        """Extract structured recommendations from response"""
        try:
            # Simple extraction - could be enhanced
            recommendations = {}
            
            if "ENSA" in response_text:
                recommendations["ecoles_recommandees"] = ["ENSA"]
            if "EMSI" in response_text:
                recommendations.setdefault("ecoles_recommandees", []).append("EMSI")
            if "ISPITS" in response_text:
                recommendations.setdefault("ecoles_recommandees", []).append("ISPITS")
                
            return recommendations if recommendations else None
            
        except Exception:
            return None